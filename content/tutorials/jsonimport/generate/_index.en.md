---
title: "Generating JSON Payloads"
menu:
  main:
    name: "Generating JSON Payloads"
    identifier: "tutorials/jsonimport/generate"
    parent: "tutorials/jsonimport"
---

# Generating JSON Payloads

> The example that is given here can only be considered as one of many possible solutions.
>
> Each source material needs specialized tools to convert the data into payloads. Basically, any source can be read and converted using any script or programming language.

In this example, the way to convert data from a database dump in CSV format into valid JSON payloads, is described. It uses a [helper tool](https://github.com/programmfabrik/easydb-migration-tools) to generate a sqlite database from various input sources, and a python script that reads the sqlite database and writes JSON files.

### Requirements

To perform the migration, that is described here, you need the following tools:

* git
* Python 2.7

It is helpful to install the [DB Browser for SQLite](https://sqlitebrowser.org/dl/) to look into the generated database. Otherwise, the commandline tool `sqlite3` can be used.

## Sources

To describe the necessary steps, let's assume the following scenario: There is a CSV dump from some database system, that we use as the source.

* One file, `orte.csv`, contains the hierarchic geographical names, including the child-parent-relations (see [Linked object `orte`](../#orte-orte)): {{< include_json "./script/orte.csv" >}}

* The other file, `bilder.csv`, contains the main objects, that are used to generate the [`bilder`](../#bilder-bilder) and [`objekte`](../#objekte-objekte) objects: {{< include_json "./script/bilder.csv" >}}

The names of the places in `orte.csv` are referenced in the objects in `bilder.csv`

## Converting the CSV files to a Sqlite database

Using a sqlite database as the source for the payload script has proven to be an efficient and low-performance way to generate payloads from different sources.

### data2sqlite

Download or clone the public [easydb-migration-tools](https://github.com/programmfabrik/easydb-migration-tools) repository. From this repository, we use the `data2sqlite.py` python script. This script can convert different sources to sqlite, for example MySQL databases, XML or CSV files.

> When running the python script, you might get multiple errors for missing imports. These libraries need to be installed to be able to run the script.

The following command creates the sqlite file `migration_data.sqlite`:

```bash
./data2sqlite.py --init --target migration_data.sqlite file --CSV path/to/csv/files/orte.csv path/to/csv/files/bilder.csv
```

* `--init` overwrites any existing database files with the target filename
* `--target` is the file path where the generated sqlite file is saved
* `file --CSV` defines the input format CSV and one or more input files

### Structure of generated tables

For each CSV file, a table is created in the database:

* for `orte.csv` the table is `"source.orte.csv"`
* for `bilder.csv` the table is `"source.bilder.csv"`

These tables include all columns from the CSV files, as well as two columns that are generated by the script:

* `__source_unique_id` contains a unique id for each row in the table
* `__source_inserted_time` contains the timestamp when the data was written into the sqlite file

These are the generated tables in the sqlite file:

#### `source.orte.csv`:

| **__source_unique_id** | **__source_inserted_time** | **id** | **parent** | **name** |
|---|---|---|---|---|
| `1` | `2020-04-23 11:53:01` | `1` | | `Europa`|
| `2` | `2020-04-23 11:53:01` | `2` | `1` | `Deutschland`|
| `3` | `2020-04-23 11:53:01` | `3` | `2` | `Berlin`|
| `4` | `2020-04-23 11:53:01` | `4` | `2` | `Brandenburg`|

#### `source.bilder.csv`:

| **__source_unique_id** | **__source_inserted_time** | **inventarnummer** | **data-from** | **date-to** | **title-de** | **title-en** | **image** | **date** | **ort** | **fotograf** | **schlagworte** |**public** |
|---|---|---|---|---|---|---|---|---|---|---|---|---|
| `1` | `2020-04-23 11:53:01` | `987654321` | `1.4.2020` | `8.4.2020` | `Berliner Fernsehturm` | `Berlin TV Tower` | `https://images.unsplash.com/photo-1560930950-5cc20e80e392?w=800&q=80` | `6.4.2020` | `Berlin` | `Max Mustermann` | `Stadt;Panorama`| `true` |
| `2` | `2020-04-23 11:53:01` | `112233` | `1.4.2020` | `7.4.2020` | `Berglandschaft` | | `https://images.unsplash.com/photo-1583268426351-53cd67fefed9?w=600&q=80` | `1.4.2020` | | | `Panorama`| `true` |

## Python script

This is the python script that reads the sqlite database and generates the migration payloads. All the logic is in this file, the mapping of database fields into easydb fields happens in the code.

### Imports

We need the following packages:

```python
import sqlite3
import json
import datetime
import sys
```

We also use some helper functions from `easydb-migration-tools`. To include these, the path to the repository needs to be added to the system paths:

```python
sys.path.append('path/to/easydb-migration-tools/json_migration/')
import migration_util
```

Replace `path/to/` with the folder where you cloned `easydb-migration-tools`.

### Helper functions

The date format in the CSV has a different format than the easydb format for date values: `1.4.2020` (`dd.mm.YYYY`), which can not be saved in the database. The date must be parsed and reformatted in the form `2020-04-01` (`YYYY-mm-dd`).

The following helper function parses the date string from the database and uses the format, which is defined in the `migration_util` package:

```python
def format_date(input):
    try:
        d = datetime.datetime.strptime(input, '%d.%m.%Y')
        return migration_util.datetime_to_date(d)
    except Exception as e:
        return None
```

The return value of this function can directly be used in the payload. If the input date string is invalid and can not be parsed, this function returns `None`, which will be `null` in the payload and which is a valid easydb value.

### Reading from sqlite

To connect to the sqlite database, we have to import the package:


